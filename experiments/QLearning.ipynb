{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning\n",
    "\n",
    "or *using Graph Reinforcement Learning to automate geometric design*\n",
    "\n",
    "Key developments:\n",
    "* I developed \"new\" graph deep learning package (borrowed heavily from Pytorch Geometric and Google Deepmind's GraphNets paper). Like GraphNets, implements Graph Convolutional Networks, Message Passing, Deep Sets, etc. but in a very flexible API built around pytorch.\n",
    "* Implement Bayesian Deep Nets and apply them to graph data.\n",
    "* Demonstate ability simulate chemical reaction networks from steady state data (easy to collect). Calculates which parts we are *certain* of their behavior and which parts of the network we are *certain* of.\n",
    "* Developed RL (Double-Q Learning + Bayesian + Geometric) based approach to *design* genetic circuits given a specification and learned part behavior.\n",
    "* Discussion on applications of this approach for uncertain geometric design "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric and Graph Deep Learning?\n",
    "\n",
    "Lots of things can be represented as graphs. Knowledge. Protein interactions. Social networks. Basically, a 'graph' here is a tensor of node features, a tensor of edge features, a tensor of directed edges indicating node-to-node interactions, and finally a tensor of global graph attributes.\n",
    "\n",
    "As an example, a 3D object could be represented as a graph. Each vertex in the polygons that assemble the object may have a 3-dimensional tensor indicating its position in space. Perhaps it also has a 1-dimensional tensor indicating the distance between nodes. Maybe another global tensor indicating the category this object is (e.g. face, cat, dog, etc.). The tensor'd representation is then a 4D tensor (3d for each node), a 2D tensor (1D for each edge), and a 1D tensor (1 graph, 1 feature).\n",
    "\n",
    "Geometric loosely here, means \"represented as a graph.\" Typically, a graph with node and positions space and/or edges with distances or other features. I loosely use this term for all types of graph data even though it is  not accurate to distinguish the terminology from other types of graphs (such as the underlying computation graph deep learning frameworks like Pytorch use). You can think of all graphs as being 'geometric' is different types of dimensional space since we can arbitrary use different dimensions and still maintain the interactions b\n",
    "\n",
    "**Difference between Euclidean and Geometric DL**\n",
    "\n",
    "Traditionally, data is represented as a multi-dimensional table. \n",
    "\n",
    "For images, the *locality* of the data is clearly important. Hence, all of the variants of convolutional neural networks. Really, you can think of CNN as extracting local information at each position.\n",
    "\n",
    "Going a step further, imagine you could blah blah blah.\n",
    "\n",
    "**What does it mean to train a DL model on graphs**\n",
    "\n",
    "Generally, we input a graphs with features and are trying to train the network to learn target graph features. This could be limited to just node features, edge_features, global features, or any combination of those. The key development here is how we relate different layers in to the interactions of the graphs. This is what my library does. Including optimized code to run quickly on a GPU (this code run painfully VERY slowly on CPUs)\n",
    "\n",
    "**Generic Message Passaging Deep Learning**\n",
    "\n",
    "A message passing network is a network that passes information between layers according to list of edges.\n",
    "\n",
    "We pass edge attributes, 'aggregate' information to the node attribute later. Then aggregate the edge and node information to the global layer. We can repeat this process for as many steps as we want. We can also choose what types of layers exist at the node, edge, and global levels. We can also choose to aggregate, or not aggregate the information at each step. During the learning process, the layers will decide which information is relevant to pass from edge->node, node->global, edge->global.\n",
    "\n",
    "[picture of edge aggregation](pic)\n",
    "\n",
    "For example, if we choose NOT to aggregate information, we get a graph encoding of the input graphs. If we do aggregate the edge levels, we begin passing information from the edge to the node level. If we repeat the process, message are passed throughout the graph. \n",
    "\n",
    "**Genetic Networks as directed graphs**\n",
    "\n",
    "This makes sense for representing something like a interaction networks in biology, which we often represent as directed network. \n",
    "\n",
    "[picture of interaction network]\n",
    "\n",
    "Imagine node features could be something like GO terms, sequences. Edge features should be *how* something interacts. Global features could be organism behavior (e.g. flourescence). example 2. You can see how this type of representation is very flexible and makes a Geometric Deep Learning framework potentially very powerful for all kinds of biological data.\n",
    "\n",
    "**In Silico simulation of learning part behavior from steady state data**\n",
    "\n",
    "We can learn any type of generic function just from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Deep Learning\n",
    "\n",
    "Pyro, Uber's probalistic programming language.\n",
    "\n",
    "I do not have time to go over the details, however, ins\n",
    "\n",
    "Review of epistemic (model) vs aleatoric (data) uncertainty\n",
    "\n",
    "What about \"these\" data points. The problem with predictive models in Deep Learning is that there is no concept of uncertainty. What this model is saying is that, \"this is the most statistically likely value with unknown certainty.\" Are we really confortable use such a model? As far as we know, we are going to take the outputs as truth.\n",
    "\n",
    "An alternative would be to create a deep model that not only gives use our most likely output, but also uncertainties associated with it, so we can appropriately evaluate whether we want to use the output data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "Black-box models. A common criticism for models. However, with things like ODE models, how much does it really *explain*. Its a way to fit the data into a mental and mathematical model. However, just because the data fits the mental model, doesn't mean its an explaination. (How many times have we created a 'model' only to find out it doesn't fit when we perform new experiment where we try to 'tweek' one of the parameters). Then in, what way was the model an explaination? \n",
    "\n",
    "Should everything be expressed as an ODE model? As we add more components to decribe anomalies in out data, the model becomes more and more complicated and it becomes easier and easier to fix multiple different parameters to the same data. Hence, we are in a balance between explainability and predictability. The more complex our model is, the less explaination it gives and the more\n",
    "\n",
    "If we develop a black box model that accurately predicts the data, isn't that pretty good? Moreover, there *are* ways to tease how what the model has learned. This is where bayesian portion comes in, we can determine where exactly the uncertainty is for the outputs it generates, which is immensely useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    def sample(self, batch_size):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from caldera.data import GraphData\n",
    "from typing  import *\n",
    "\n",
    "\n",
    "class Transition(object):\n",
    "    \n",
    "    __slots__ = ['state', 'action', 'next_state', 'reward']\n",
    "    \n",
    "    def __init__(self, state, action, next_state, reward):\n",
    "        self.state = state\n",
    "        self.action =  action\n",
    "        self.next_state = next_state\n",
    "        self.rewarrd = reward\n",
    "        \n",
    "        \n",
    "class GraphTransition(Transition):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity, transition_type: Type[Transition] = Transition):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        self.transition_type = transition_type\n",
    " \n",
    "\n",
    "    def push(self, *args):\n",
    "            \"\"\"Saves a transition.\"\"\"\n",
    "            if len(self.memory) < self.capacity:\n",
    "                self.memory.append(None)\n",
    "            self.memory[self.position] = self.transition_type(*args)\n",
    "            self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "        def sample(self, batch_size):\n",
    "            return random.sample(self.memory, batch_size)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.memory)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    \"\"\"The environment the designer Agent exists in\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._memory = None\n",
    "        self.model = None\n",
    "        self.state = None\n",
    "        \n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "    \n",
    "    def attach_memory(self, memory):\n",
    "        self._memory = memory\n",
    "    \n",
    "    def step(self, action: int):\n",
    "        \"\"\"Select and perform the given action\"\"\"\n",
    "        # this is where we modify the circuit, re-run the simulation\n",
    "        # if memory is attached, we save the Transition\n",
    "        # we return the Transition and reward\n",
    "        \n",
    "        # Progression:\n",
    "        # step 1: we start off with a simple Oracle simulation that is 100% accurate\n",
    "        # step 2: we use learned uncertain parameters from results, there is a penalty for usage of \n",
    "        # uncertain parts, but this is a parameter we can explore.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.models import GraphEncoder, GraphCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from caldera.blocks import MLP\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    We will be given a GraphBatch instance which will contain an\n",
    "    arbitrary number of graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_actions):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(MLP(16, n_actions))\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, graph_data, desired_behavior):\n",
    "        \"\"\"Here we take in the current graph and desired_behavior and return the probability\n",
    "        of actions.\"\"\"\n",
    "        return self.encoder(graph_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-97adb90d885b>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-97adb90d885b>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    # this is another comments\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "n_actions = 10\n",
    "policy_net = DQN(n_actions)\n",
    "target_net = DQN(n_actions)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    # this is a comment \n",
    "    # this is a comment \n",
    "    # this is another comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    \n",
    "    batch = Transition(*zip(*transitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actions:**\n",
    "\n",
    "\n",
    "* Swap node \n",
    "* Add node\n",
    "* swap nodes\n",
    "* swap edges\n",
    "* Remove node\n",
    "* Add edge``\n",
    "* Terminate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action space\n",
    "\n",
    "here we define the action space as modifications to the graph representing the circuit network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action():\n",
    "    \"\"\"selects the next action \"\"\"\n",
    "\n",
    "    passlamar;lamar\n",
    "\n",
    "\n",
    "def select_action():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
