{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/sparse/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           tensortype\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from typing import *\n",
    "\n",
    "\n",
    "# torch.sparse.LongTensor?\n",
    "# @torch.jit.script\n",
    "# def foo(arr: torch.Tensor, idx_dict: Dict[int, list], ele_dict: Dict[int, torch.Tensor]) -> Dict[int, torch.Tensor]:\n",
    "    for idx, x in enumerate(arr):\n",
    "        k = x.item()\n",
    "        if k not in idx_dict:\n",
    "            idx_dict[k] = []\n",
    "        idx_dict[k] += [idx]\n",
    "#     for k, v in idx_dict.items():\n",
    "#         ele_dict[k] = torch.tensor(v, dtype=torch.long)\n",
    "#     return ele_dict\n",
    "\n",
    "arr = torch.tensor([0, 0, 1, 2, 3])\n",
    "\n",
    "out = torch.spare.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 ms ± 36.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "tensor([ 0.0798, -1.5222,  0.6170, -1.3649, -0.0736,  0.2720,  1.6178, -1.3368,\n",
      "        -1.2623, -0.0814])\n",
      "tensor([4, 1, 5, 1, 1, 3, 2, 2, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6.]),\n",
       " [tensor([-1.5222, -1.3649, -0.0736]),\n",
       "  tensor([ 1.6178, -1.3368]),\n",
       "  tensor([0.2720]),\n",
       "  tensor([0.0798]),\n",
       "  tensor([ 0.6170, -1.2623]),\n",
       "  tensor([-0.0814])])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def unique_with_counts(idx, grouped: Dict[int, int]):\n",
    "    for x in idx:\n",
    "        if x.item() not in grouped:\n",
    "            grouped[x.item()] = 1\n",
    "        else:\n",
    "            grouped[x.item()] += 1\n",
    "            \n",
    "    counts = torch.zeros(len(grouped), dtype=torch.long)\n",
    "    values = torch.empty(len(grouped))\n",
    "    for i, (k, v) in enumerate(grouped.items()):\n",
    "        values[i] = k\n",
    "        counts[i] = v\n",
    "    a = torch.argsort(values)\n",
    "    \n",
    "    return values[a], counts[a]\n",
    "\n",
    "@torch.jit.script\n",
    "def scatter_group(x: torch.Tensor, idx: torch.Tensor, d: Dict[int, int]) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "    x = x[torch.argsort(idx)]\n",
    "    groups, b = unique_with_counts(idx, d)\n",
    "    i_a = 0\n",
    "    arr_list = []\n",
    "    for i_b in b:\n",
    "        arr_list.append(x[i_a:i_a + i_b.item()])\n",
    "        i_a += i_b.item()\n",
    "    return groups, arr_list\n",
    "\n",
    "\n",
    "l = 1000\n",
    "idx = torch.randint(0, l, torch.Size([l]), dtype=torch.long)\n",
    "x = torch.randn(l)\n",
    "\n",
    "scatter_group(x, idx, {})\n",
    "# idx\n",
    "%timeit -n 10 scatter_group(x, idx, {})\n",
    "# print(idx)\n",
    "# unique_with_counts(idx, {})\n",
    "l = 10\n",
    "idx = torch.randint(0, l, torch.Size([l]), dtype=torch.long)\n",
    "x = torch.randn(l)\n",
    "print(x)\n",
    "print(idx)\n",
    "\n",
    "b = scatter_group(x, idx, {})\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_batch_to_nx(batch):\n",
    "    gidx_1, node_attrs = scatter_group(batch.x, batch.node_idx)\n",
    "    gidx_2, edge_attrs = scatter_group(batch.e, batch.edge_idx)\n",
    "    for k, n in zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([2, 1, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(arr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0]), tensor([1]), tensor([2]), tensor([3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(arr, [2, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
